\documentclass[10pt]{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}%
\setbeamersize{text margin left=0.5cm, text margin right=0.5cm}

\usepackage{alltt}%
\usetheme[background=light]{metropolis} 
\usecolortheme{seahorse}

\usepackage[utf8]{inputenc}%


\usepackage[normalem]{ulem}%strikeout
 

% graphics
%% Figures %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}
\usepackage{xcolor}%for color mixing

\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}

\usepackage{tikz}
\usetikzlibrary{calc}

\usepackage{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%% Doc info %%%%%%%%%%%%%%%%%%%
\title{Multiple regressions}
\author{Timoth\'ee Bonnet}
\institute{BDSI / RSB}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}



\begin{frame}
  \begin{quote}
  ``Simple and multiple regression are two of the most-used statistical procedures in biology. Statistical results from both procedures are commonly interpreted as metrics of the degree of relationship between (sometimes multiple) explanatory and response variables. This rough interpretation may generally be satisfactory for simple regressions, i.e., models involving only one explanatory variable. However, this interpretation can lead to confusion for multiple regression, where the coefficients of a multiple regression model measure something subtly but crucially different\dots"
  \end{quote}
Morrissey \& Ruxton (2018) \textbf{Multiple Regression Is Not Multiple Regressions: The Meaning of Multiple Regression and the Non-Problem of Collinearity}. PTPBIO 10(3)

\end{frame}
%%%%%%%%%%%

\begin{frame}
\maketitle
\end{frame}
%%%%%%%%%%%


\AtBeginSection[]
{
  \begin{frame}<beamer>
    \Large
    \frametitle{}
    \tableofcontents[currentsection,hideothersubsections,subsectionstyle=hide]% down vote\tableofcontents[currentsection,currentsubsection,hideothersubsections,sectionstyle=show/hide,subsectionstyle=show/shaded/hide]
  \end{frame}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Linear model, reminder}

\begin{frame}[fragile]{A simple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope}} $\times$ {\color{orange}{Predictor}} + {\color{gray}{Error}}} \\

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.8\textwidth,height=0.6\textwidth]{figure/lmprinc0-1} 

\end{knitrout}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{A multiple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope1}} $\times$ {\color{orange}{Predictor1}} + {\color{red}{Slope2}} $\times$ {\color{orange}{Predictor2}}  + {\color{gray}{Error}}} \\
  \vspace{1cm}
\textbf{In R:}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{lm}\hlstd{(response} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{predictor1} \hlopt{+} \hlstd{predictor2,} \hlkwc{data}\hlstd{=data)}
\end{alltt}
\end{kframe}
\end{knitrout}


\end{frame}
%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multiple regression}

\begin{frame}[fragile]{Sequential regression}


  
We want to explain a response by three predictors
\only<2>{
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.8\textwidth,height=0.6\textwidth]{figure/lmprinc1-1} 

\end{knitrout}
}
\only<3>{
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.8\textwidth,height=0.6\textwidth]{figure/lmprinc2-1} 

\end{knitrout}
}
\only<4>{
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.8\textwidth,height=0.6\textwidth]{figure/lmprinc3-1} 

\end{knitrout}
}

\end{frame}
%%%%%%%%%%%



\begin{frame}[fragile]{Sequential regression}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{m1} \hlkwb{<-} \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1)}
  \hlstd{m2} \hlkwb{<-} \hlkwd{lm}\hlstd{(m1}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x2)}
  \hlstd{m3} \hlkwb{<-} \hlkwd{lm}\hlstd{(m2}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x3)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Sequential regression}

But estimates in
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{m1} \hlkwb{<-} \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1)}
  \hlstd{m2} \hlkwb{<-} \hlkwd{lm}\hlstd{(m1}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x2)}
  \hlstd{m3} \hlkwb{<-} \hlkwd{lm}\hlstd{(m2}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x3)}
  \hlkwd{c}\hlstd{(}\hlkwd{coefficients}\hlstd{(m1)[}\hlnum{2}\hlstd{],} \hlkwd{coefficients}\hlstd{(m2)[}\hlnum{2}\hlstd{],} \hlkwd{coefficients}\hlstd{(m3)[}\hlnum{2}\hlstd{])}
\end{alltt}
\begin{verbatim}
       x1        x2        x3 
1.5080427 0.8163980 0.2397068 
\end{verbatim}
\end{kframe}
\end{knitrout}
are different from
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlstd{m1} \hlkwb{<-} \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x3)}
    \hlstd{m2} \hlkwb{<-} \hlkwd{lm}\hlstd{(m1}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x2)}
    \hlstd{m3} \hlkwb{<-} \hlkwd{lm}\hlstd{(m2}\hlopt{$}\hlstd{residuals} \hlopt{~} \hlstd{x1)}
    \hlkwd{c}\hlstd{(}\hlkwd{coefficients}\hlstd{(m1)[}\hlnum{2}\hlstd{],} \hlkwd{coefficients}\hlstd{(m2)[}\hlnum{2}\hlstd{],} \hlkwd{coefficients}\hlstd{(m3)[}\hlnum{2}\hlstd{])}
\end{alltt}
\begin{verbatim}
        x3         x2         x1 
-0.6143369  1.4517052  0.3677874 
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%%
\begin{frame}[fragile]{Sequential regression}
  Also what happens with classical ANOVA (aov in R)
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{summary}\hlstd{(}\hlkwd{aov}\hlstd{(y} \hlopt{~} \hlstd{x1} \hlopt{+} \hlstd{x2} \hlopt{+} \hlstd{x3))}
\end{alltt}
\begin{verbatim}
            Df Sum Sq Mean Sq F value   Pr(>F)    
x1           1  40.88   40.88 251.862 3.27e-11 ***
x2           1  16.40   16.40 101.051 2.55e-08 ***
x3           1   0.02    0.02   0.135    0.719    
Residuals   16   2.60    0.16                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\begin{alltt}
  \hlkwd{summary}\hlstd{(}\hlkwd{aov}\hlstd{(y} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3} \hlopt{+} \hlstd{x1))}
\end{alltt}
\begin{verbatim}
            Df Sum Sq Mean Sq F value   Pr(>F)    
x2           1  46.20   46.20  284.62 1.30e-11 ***
x3           1   2.46    2.46   15.16  0.00129 ** 
x1           1   8.65    8.65   53.27 1.79e-06 ***
Residuals   16   2.60    0.16                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Multiple regression}
In contrast lm() optimizes relationships simultaneously\\
Order does \textbf{not} matter:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{coefficients}\hlstd{(}\hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1} \hlopt{+} \hlstd{x2} \hlopt{+} \hlstd{x3))}
\end{alltt}
\begin{verbatim}
(Intercept)          x1          x2          x3 
 0.45794446  0.94570383  1.12062799  0.03583753 
\end{verbatim}
\begin{alltt}
  \hlkwd{coefficients}\hlstd{(}\hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x2} \hlopt{+} \hlstd{x3} \hlopt{+} \hlstd{x1))}
\end{alltt}
\begin{verbatim}
(Intercept)          x2          x3          x1 
 0.45794446  1.12062799  0.03583753  0.94570383 
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Multiple regression}
\textbf{BUT} estimates may change with extra covariates
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{coefficients}\hlstd{(}\hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1} \hlopt{+} \hlstd{x2 ))}
\end{alltt}
\begin{verbatim}
(Intercept)          x1          x2 
  0.4625304   0.9214930   1.1242262 
\end{verbatim}
\begin{alltt}
    \hlkwd{coefficients}\hlstd{(}\hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1} \hlopt{+} \hlstd{x2} \hlopt{+} \hlstd{x3))}
\end{alltt}
\begin{verbatim}
(Intercept)          x1          x2          x3 
 0.45794446  0.94570383  1.12062799  0.03583753 
\end{verbatim}
\end{kframe}
\end{knitrout}
\pause
\begin{block}{??}
  \begin{itemize}
    \item That is a good thing
    \item Estimates are independent effects, conditional on the other parameters
  \end{itemize}
\end{block}
\end{frame}
%%%%%%%%%%%



\begin{frame}[fragile]{Multiple regression}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
        \hlkwd{library}\hlstd{(}\hlstr{"plot3D"}\hlstd{)}
\hlstd{fit} \hlkwb{<-} \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlstd{x1} \hlopt{+} \hlstd{x2)}
\hlcom{# predict values on regular xy grid}
\hlstd{grid.lines} \hlkwb{=} \hlnum{26}
\hlstd{x1.pred} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlkwd{min}\hlstd{(x1),} \hlkwd{max}\hlstd{(x1),} \hlkwc{length.out} \hlstd{= grid.lines)}
\hlstd{x2.pred} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlkwd{min}\hlstd{(x2),} \hlkwd{max}\hlstd{(x2),} \hlkwc{length.out} \hlstd{= grid.lines)}
\hlstd{x1x2} \hlkwb{<-} \hlkwd{expand.grid}\hlstd{(} \hlkwc{x1} \hlstd{= x1.pred,} \hlkwc{x2} \hlstd{= x2.pred)}
\hlstd{y.pred} \hlkwb{<-} \hlkwd{matrix}\hlstd{(}\hlkwd{predict}\hlstd{(fit,} \hlkwc{newdata} \hlstd{= x1x2),}
                 \hlkwc{nrow} \hlstd{= grid.lines,} \hlkwc{ncol} \hlstd{= grid.lines)}
\hlstd{fitpoints} \hlkwb{<-} \hlkwd{predict}\hlstd{(fit)}
\hlkwd{scatter3D}\hlstd{(x1, x3, y,} \hlkwc{pch} \hlstd{=} \hlnum{18}\hlstd{,} \hlkwc{cex} \hlstd{=} \hlnum{2}\hlstd{,}
    \hlkwc{theta} \hlstd{=}\hlnum{18}\hlstd{,} \hlkwc{phi} \hlstd{=} \hlopt{-}\hlnum{18}\hlstd{,} \hlkwc{ticktype} \hlstd{=} \hlstr{"detailed"}\hlstd{,}
    \hlkwc{xlab} \hlstd{=} \hlstr{"x1"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"x2"}\hlstd{,} \hlkwc{zlab} \hlstd{=} \hlstr{"y"}\hlstd{,}
    \hlkwc{surf} \hlstd{=} \hlkwd{list}\hlstd{(}\hlkwc{x} \hlstd{= x1.pred,} \hlkwc{y} \hlstd{= x2.pred,} \hlkwc{z} \hlstd{= y.pred,}
    \hlkwc{facets} \hlstd{=} \hlnum{NA}\hlstd{,} \hlkwc{fit} \hlstd{= fitpoints),} \hlkwc{main} \hlstd{=} \hlstr{""}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
    \end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Multiple regression}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.8\textwidth,height=0.6\textwidth]{figure/unnamed-chunk-10-1} 

\end{knitrout}
    \end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Multiple regression}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{library}\hlstd{(}\hlstr{"plot3Drgl"}\hlstd{)}
\hlkwd{plotrgl}\hlstd{(}\hlkwc{lighting} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{new}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Conditional estimation}

\begin{exampleblock}{Exercise 1}
  \begin{enumerate}
    \item load \texttt{jumpingdistance.csv}
    \item Use plots and lm() to test whether mass increases jumping distance
  \end{enumerate}
\end{exampleblock}



\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{jumping} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlkwc{file} \hlstd{=} \hlstr{"jumpingdistance.csv"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

A first approach suggests mass increases jumping distance:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(jump} \hlopt{~} \hlstd{mass,} \hlkwc{data}\hlstd{=jumping))}
    \hlkwd{plot}\hlstd{(mass, jump)}
\end{alltt}
\end{kframe}
\end{knitrout}
  
But that is incorrect and due to the correlation between mass and height:
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(jump} \hlopt{~} \hlstd{mass} \hlopt{+} \hlstd{height,} \hlkwc{data}\hlstd{=jumping))}
\end{alltt}
\end{kframe}
\end{knitrout}
The direct (causal) effect of mass is negative, as revealed by a multiple regression

\end{frame}
%%%%%%%%%%%

\begin{frame}{Conditional estimation}
  \begin{center}
  \begin{tikzpicture}
  \node (cor) at (-8, 2) {Total / marginal effects};
    \node (jump1) at (-6,0) {jumping distance};
    \node (height1) at (-9, 1) {height};
    \node (mass1) at (-9, -1) {mass};
    \draw[->, thick, color=red] (height1) -- (jump1);
    \draw[->, thick, color=red] (mass1) -- (jump1);

  \draw[dashed] ($(jump1.east)+(0.2,2)$)-- ($(jump1.east)+(0.2,-2)$);
  
  \pause
  
    \node (caus) at (-2, 2) {Direct / conditional effects};
    \node (jump) at (0,0) {jumping distance};
    \node (height) at (-3, 1) {height};
    \node (mass) at (-3, -1) {mass};
    \draw[->, ultra thick, color=red] (height) -- (jump);
    \draw[->, color=blue] (mass) -- (jump);
    \draw[->, color=red, thick] (height)--(mass);
  \end{tikzpicture}
  \end{center}
  
  \uncover<2>{
  \begin{itemize}
    \item Marginal effects $\approx$ raw correlations, sum of direct and indirect effects
    \item Multiple regression estimates direct effects (conditional on other predictors) $\rightarrow$ may reveal causal relationships
  \end{itemize}}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Conditional estimation}

  
  \begin{exampleblock}{Exercise 2}
    \begin{enumerate}
      \item Load \texttt{babies.csv}
      \item What drives change in number of babies born?
    \end{enumerate}
  \end{exampleblock}
  
  
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Conditional estimation warning: more covariates is not always better}

  
  \textbf{Are more innovative papers less rigorous?}
  \begin{center}
  \begin{tikzpicture}
    \node (cor) at (-8, 2) {Research question};
    \node (rig) at (-9,-1) {Scientific rigor};
    \node (innov) at (-9, 1) {Innovativeness};
    \draw[->, color=blue] (innov)--(rig);
    \node (qm) at (-8.8,0) {\textbf{?}};
    
    \pause
    \node (impact) at (-6, 0) {Impact};
    \draw[->, color=red, thick] (rig)--(impact);
    \draw[->, color=red, thick] (innov)--(impact);
    
  \end{tikzpicture}
  \end{center}
  
  \textit{Should you correct for publication impact?}
  
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Conditional estimation final warning: more is not always better}
    \textit{Should you include publication impact?}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(rigor} \hlopt{~} \hlstd{innovativeness} \hlopt{+} \hlstd{impact))}\hlopt{$}\hlstd{coefficients}
\end{alltt}
\begin{verbatim}
                 Estimate Std. Error    t value      Pr(>|t|)
(Intercept)     0.0301366 0.02188752   1.376885  1.688569e-01
innovativeness -0.3150363 0.03051417 -10.324262  8.238502e-24
impact          0.5135830 0.01538756  33.376503 1.361378e-164
\end{verbatim}
\end{kframe}
\end{knitrout}
  Apparent {\color{blue}{negative}} effect of innovativeness ?

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
    \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(rigor} \hlopt{~} \hlstd{innovativeness))}\hlopt{$}\hlstd{coefficients}
\end{alltt}
\begin{verbatim}
                 Estimate Std. Error   t value     Pr(>|t|)
(Intercept)    0.04104524 0.03182923  1.289545 1.975073e-01
innovativeness 0.38804729 0.03210760 12.085841 1.758144e-31
\end{verbatim}
\end{kframe}
\end{knitrout}
    Apparent {\color{red}{positive}} effect of innovativeness ?
    
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Conditional estimation final warning: more is not always better}
    \textit{Should you include publication impact?}

  \pause
  Data simulated with positive effect of innovativeness on rigor (simulated slope 0.3)\\ \pause
  \textbf{You should NOT correct for impact}\\ \bigskip \pause
  \textbf{\large \color{red} Rule of Thumb: Do not correct for variables influenced by your predictor outside the causal path of interest}
\end{frame}
%%%%%%%%%%%

\begin{frame}{}

\end{frame}
%%%%%%%%%%%

\begin{frame}{Want more on multiple regression?}

Morrissey \& Ruxton (2018) \textbf{Multiple Regression Is Not Multiple Regressions: The Meaning of Multiple Regression and the Non-Problem of Collinearity}. PTPBIO 10(3)

{\color{blue} \href{dx.doi.org/10.3998/ptpbio.16039257.0010.003}{dx.doi.org/10.3998/ptpbio.16039257.0010.003}}
 
 \begin{quote}
 Simple regression, and multiple regression, typically correspond to very different biological questions. The former use regression lines to describe univariate associations. The latter describe the partial, or direct, effects of multiple variables, conditioned on one another. We suspect that the superficial similarity of simple and multiple regression leads to confusion in their interpretation. [\dots] There is no general sense in which collinearity is a problem. [\dots] Purported solutions to the perceived problems of collinearity are detrimental to most biological analyses.
 \end{quote}
\end{frame}
%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Interaction}

\begin{frame}[fragile]{Warnings}

  \begin{alertblock}{Vocabulary warning!}
    \begin{itemize}[<+->]
      \item \textbf{correlation}: linear association between two variables \textit{"how well does $x$ explain $y$ ?"}
      \item \textbf{interaction}: non-additive effect of two or more variables \textit{"does the effect of $x_1$ on $y$ change as a function of $x_2$?"}. Adds a predictor (or several) to a model.
    \end{itemize}
  \end{alertblock}

\pause
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.6\textwidth,height=0.6\textheight]{figure/histinter-1} 

\end{knitrout}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Fitting an interaction}


\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{x1} \hlopt{*} \hlstd{x2)}
  \hlkwd{lm}\hlstd{(y} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{x1} \hlopt{+} \hlstd{x2} \hlopt{+} \hlstd{x1}\hlopt{:}\hlstd{x2)}
\end{alltt}
\end{kframe}
\end{knitrout}
  \pause
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(y}\hlopt{~} \hlnum{1} \hlopt{+} \hlstd{x1}\hlopt{*}\hlstd{x2))}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = y ~ 1 + x1 * x2)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8719 -0.6777 -0.1086  0.5897  2.3166 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.14098    0.09578  11.913  < 2e-16 ***
x1          -0.49281    0.10834  -4.549 1.58e-05 ***
x2           0.53434    0.09881   5.408 4.67e-07 ***
x1:x2        0.35911    0.11449   3.137  0.00227 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9468 on 96 degrees of freedom
Multiple R-squared:  0.4252,	Adjusted R-squared:  0.4072 
F-statistic: 23.67 on 3 and 96 DF,  p-value: 1.49e-11
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Fitting an interaction}
Why the multiplication sign?
\pause
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{x1Xx2} \hlkwb{<-} \hlstd{x1}\hlopt{*}\hlstd{x2}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
     \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(y}\hlopt{~} \hlnum{1} \hlopt{+} \hlstd{x1} \hlopt{+} \hlstd{x2} \hlopt{+} \hlstd{x1Xx2))}
\end{alltt}
\begin{verbatim}

Call:
lm(formula = y ~ 1 + x1 + x2 + x1Xx2)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8719 -0.6777 -0.1086  0.5897  2.3166 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.14098    0.09578  11.913  < 2e-16 ***
x1          -0.49281    0.10834  -4.549 1.58e-05 ***
x2           0.53434    0.09881   5.408 4.67e-07 ***
x1Xx2        0.35911    0.11449   3.137  0.00227 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9468 on 96 degrees of freedom
Multiple R-squared:  0.4252,	Adjusted R-squared:  0.4072 
F-statistic: 23.67 on 3 and 96 DF,  p-value: 1.49e-11
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{frame}
%%%%%%%%%%%


\begin{frame}[fragile]{Warnings}
  \begin{alertblock}{Modeling warning!}
    \begin{itemize}
      \item \sout{DO NOT COMPARE P-VALUES OF TWO MODELS TO TEST FOR AN INTERACTION}
    \end{itemize}
  \end{alertblock}





  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load the data masssex.csv
      \item Fit a simple regression explaining movement by mass for each sex separately. Is the relationship different between sexes?
      \item Fit the multiple regression explaining movement by mass, sex, and mass:sex, using the full dataset. Is the relationship different between sexes?
      \item Try to understand the discreapancy by plotting the data
    \end{enumerate}
  \end{exampleblock}

\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{Warnings}
1.
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{masssex} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlkwc{file}\hlstd{=}\hlstr{"masssex.csv"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
2.
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(movement} \hlopt{~} \hlstd{mass,} \hlkwc{data}\hlstd{=masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{0}\hlstd{,]))}
  \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(movement} \hlopt{~} \hlstd{mass,} \hlkwc{data}\hlstd{=masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{1}\hlstd{,]))}
\end{alltt}
\end{kframe}
\end{knitrout}
\pause
3.
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{summary}\hlstd{(}\hlkwd{lm}\hlstd{(movement} \hlopt{~} \hlstd{mass}\hlopt{*}\hlstd{sex,} \hlkwc{data}\hlstd{=masssex))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%%
\begin{frame}[fragile]{Warnings}
4. Visualize the problem (result on next slide):
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{0}\hlstd{,}\hlstr{"mass"}\hlstd{],masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{0}\hlstd{,}\hlstr{"movement"}\hlstd{],}
 \hlkwc{col}\hlstd{=}\hlstr{"blue"}\hlstd{,} \hlkwc{xlim}\hlstd{=}\hlkwd{range}\hlstd{(masssex}\hlopt{$}\hlstd{mass),} \hlkwc{ylim}\hlstd{=}\hlkwd{range}\hlstd{(masssex}\hlopt{$}\hlstd{movement),}
   \hlkwc{xlab}\hlstd{=}\hlstr{"mass"}\hlstd{,} \hlkwc{ylab}\hlstd{=}\hlstr{"movement"}\hlstd{)}
\hlkwd{points}\hlstd{(masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{1}\hlstd{,}\hlstr{"mass"}\hlstd{],}
       \hlstd{masssex[masssex}\hlopt{$}\hlstd{sex}\hlopt{==}\hlnum{1}\hlstd{,}\hlstr{"movement"}\hlstd{],} \hlkwc{col}\hlstd{=}\hlstr{"red"}\hlstd{)}
\hlkwd{legend}\hlstd{(}\hlkwc{x}\hlstd{=}\hlstr{"topleft"}\hlstd{,} \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"blue"}\hlstd{,} \hlstr{"red"}\hlstd{),}
       \hlkwc{legend} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"Sex 0"}\hlstd{,} \hlstr{"Sex 1"}\hlstd{),} \hlkwc{pch}\hlstd{=}\hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
The slope of movement on mass is the same for both sexes, but the range of values is much smaller for sex 0, so that there is no power to detect a significant effect. Analysing sexes separately is unsound. You must fit an interaction in a model with both sexes to test for an interaction.

\end{frame}
%%%%%%%%%%%
\begin{frame}[fragile]{Warnings}
4.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.7\textwidth,height=0.7\textheight]{figure/intersexbehav-1} 

\end{knitrout}
\end{frame}
%%%%%%%%%%%
% 
\begin{frame}[fragile]{Prediction}


 
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
      \uncover<2>{\item Create a prediction for plant size as a function of x for two values of y}
    \end{enumerate}
  \end{exampleblock}
  
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{plantsize} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlstr{"plantsize.csv"}\hlstd{)}
\hlstd{m0} \hlkwb{<-} \hlkwd{lm}\hlstd{(plantsize} \hlopt{~} \hlstd{x_location} \hlopt{+} \hlstd{y_location,} \hlkwc{data}\hlstd{=plantsize)}
\end{alltt}
\end{kframe}
\end{knitrout}
  
\end{frame}
%%%%%%%%%%


\begin{frame}[fragile]{Prediction}

3.1. Predict
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlstd{newdata} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{x_location} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{,} \hlkwc{length.out} \hlstd{=} \hlnum{100}\hlstd{),}\hlnum{2}\hlstd{),}
                        \hlkwc{y_location} \hlstd{=} \hlkwd{c}\hlstd{(}\hlkwd{rep}\hlstd{(}\hlopt{-}\hlnum{3}\hlstd{,} \hlnum{100}\hlstd{),} \hlkwd{rep}\hlstd{(}\hlnum{4}\hlstd{,}\hlnum{100}\hlstd{)))}
  \hlstd{newdata}\hlopt{$}\hlstd{prediction} \hlkwb{<-} \hlkwd{predict}\hlstd{(m0,} \hlkwc{newdata} \hlstd{= newdata)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}
%%%%%%%%%%

\begin{frame}[fragile]{Prediction}

3.2 Visualize 
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
  \hlkwd{plot}\hlstd{(newdata}\hlopt{$}\hlstd{x_location[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==-}\hlnum{3}\hlstd{],}
       \hlstd{newdata}\hlopt{$}\hlstd{prediction[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==-}\hlnum{3}\hlstd{],}
       \hlkwc{xlab}\hlstd{=}\hlstr{"x location"}\hlstd{,} \hlkwc{ylab}\hlstd{=}\hlstr{"plant size"}\hlstd{,} \hlkwc{type}\hlstd{=}\hlstr{"l"}\hlstd{,}
       \hlkwc{ylim} \hlstd{=} \hlkwd{range}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),} \hlkwc{col}\hlstd{=}\hlstr{"blue"}\hlstd{)}
  \hlkwd{lines}\hlstd{(newdata}\hlopt{$}\hlstd{x_location[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==}\hlnum{4}\hlstd{],}
        \hlstd{newdata}\hlopt{$}\hlstd{prediction[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==}\hlnum{4}\hlstd{],} \hlkwc{col}\hlstd{=}\hlstr{"red"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.5\textwidth,height=0.5\textheight]{figure/predadditive-1} 

\end{knitrout}

  
\end{frame}
%%%%%%%%%%

\begin{frame}[fragile]{Prediction with interaction}
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
     \item Create a prediction for plant size as a function of x for two values of y and plot it
     \item Fit an interaction between x and y coordinates
     \item Create a new prediction with interaction, and plot it
    \end{enumerate}
  \end{exampleblock}
\end{frame}
%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.7\textwidth,height=0.7\textheight]{figure/predinteractive-1} 

\end{knitrout}

\end{frame}
%%%%%%%%%%
\begin{frame}[fragile]{Prediction with interaction}
  \begin{exampleblock}{Exercise}
    \begin{enumerate}
      \item Load plantsize.csv and plot the data
      \item Fit an additive model explaining plant size by x and y coordinates
     \item Create a prediction for plant size as a function of x for two values of y and plot it
     \item Fit an interaction between x and y coordinates
     \item Create a new prediction with interaction, and plot it
     \item Compare estimates and p-values across models. Do you think x location has an effect or not?
    \end{enumerate}
  \end{exampleblock}
\end{frame}
%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{m1} \hlkwb{<-} \hlkwd{lm}\hlstd{(plantsize} \hlopt{~} \hlstd{x_location} \hlopt{*} \hlstd{y_location,} \hlkwc{data}\hlstd{=plantsize)}
\hlstd{newdata} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{x_location} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{3}\hlstd{,}\hlnum{3}\hlstd{,} \hlkwc{length.out} \hlstd{=} \hlnum{10}\hlstd{),}\hlnum{10}\hlstd{),}
                 \hlkwc{y_location} \hlstd{=} \hlkwd{rep}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlopt{-}\hlnum{3}\hlstd{,}\hlnum{4}\hlstd{,} \hlkwc{length.out} \hlstd{=} \hlnum{10}\hlstd{),} \hlkwc{each}\hlstd{=}\hlnum{10}\hlstd{))}
\hlstd{newdata}\hlopt{$}\hlstd{prediction} \hlkwb{<-} \hlkwd{predict}\hlstd{(m1,} \hlkwc{newdata} \hlstd{= newdata)}
\hlkwd{plot}\hlstd{(newdata}\hlopt{$}\hlstd{x_location[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==-}\hlnum{3}\hlstd{],}
     \hlstd{newdata}\hlopt{$}\hlstd{prediction[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==-}\hlnum{3}\hlstd{],}
       \hlkwc{xlab}\hlstd{=}\hlstr{"x location"}\hlstd{,} \hlkwc{ylab}\hlstd{=}\hlstr{"plant size"}\hlstd{,} \hlkwc{type}\hlstd{=}\hlstr{"l"}\hlstd{,}
     \hlkwc{ylim} \hlstd{=} \hlkwd{range}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),} \hlkwc{col}\hlstd{=}\hlstr{"blue"}\hlstd{)}
\hlkwd{lines}\hlstd{(newdata}\hlopt{$}\hlstd{x_location[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==}\hlnum{4}\hlstd{],}
      \hlstd{newdata}\hlopt{$}\hlstd{prediction[newdata}\hlopt{$}\hlstd{y_location}\hlopt{==}\hlnum{4}\hlstd{],} \hlkwc{col}\hlstd{=}\hlstr{"red"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{frame}
%%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}\begin{kframe}
\begin{alltt}
   \hlkwd{library}\hlstd{(reshape2)}
  \hlstd{matpred} \hlkwb{<-} \hlkwd{acast}\hlstd{(newdata, x_location}\hlopt{~}\hlstd{y_location,} \hlkwc{value.var}\hlstd{=}\hlstr{"prediction"}\hlstd{)}
  \hlkwd{layout}\hlstd{(}\hlkwc{mat} \hlstd{=} \hlkwd{matrix}\hlstd{(}\hlkwc{data} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{),}\hlkwc{nrow} \hlstd{=} \hlnum{1}\hlstd{),} \hlkwc{widths} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{3}\hlstd{,}\hlnum{1}\hlstd{) )}
  \hlkwd{image}\hlstd{(}\hlkwd{t}\hlstd{(matpred),} \hlkwc{col} \hlstd{=} \hlkwd{topo.colors}\hlstd{(}\hlnum{10}\hlstd{),} \hlkwc{xlab} \hlstd{=} \hlstr{"x location"}\hlstd{,}
        \hlkwc{ylab} \hlstd{=} \hlstr{"y location"}\hlstd{)}

  \hlkwd{par}\hlstd{(}\hlkwc{mar}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{0}\hlstd{,}\hlnum{4}\hlstd{,} \hlnum{6}\hlstd{)}\hlopt{+}\hlnum{0.1}\hlstd{)}
  \hlkwd{image}\hlstd{(}\hlkwd{matrix}\hlstd{(}\hlkwc{data} \hlstd{=} \hlkwd{seq}\hlstd{(}\hlkwd{min}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),}
              \hlkwd{max}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),} \hlkwc{length.out} \hlstd{=} \hlnum{10}\hlstd{),} \hlkwc{nrow}\hlstd{=} \hlnum{1} \hlstd{),}
        \hlkwc{col}\hlstd{=}\hlkwd{topo.colors}\hlstd{(}\hlnum{10}\hlstd{),} \hlkwc{xaxt} \hlstd{=} \hlstr{"n"}\hlstd{,} \hlkwc{yaxt}\hlstd{=}\hlstr{"n"}\hlstd{,} \hlkwc{main}\hlstd{=}\hlstr{"legend"}\hlstd{)}
  \hlkwd{axis}\hlstd{(}\hlkwc{side} \hlstd{=} \hlnum{4}\hlstd{,} \hlkwc{at} \hlstd{=} \hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{0.2}\hlstd{,}\hlnum{0.4}\hlstd{,}\hlnum{0.6}\hlstd{,}\hlnum{0.8}\hlstd{,}\hlnum{1}\hlstd{),}
\hlkwc{labels} \hlstd{=} \hlkwd{round}\hlstd{(}\hlkwd{seq}\hlstd{(}\hlkwd{min}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),} \hlkwd{max}\hlstd{(newdata}\hlopt{$}\hlstd{prediction),}
                   \hlkwc{length.out} \hlstd{=}\hlnum{6}\hlstd{),}\hlnum{1}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{frame}
%%%%%%%%%%

  \begin{frame}[fragile]{Prediction with interaction}

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.843, 0.867, 0.922}\color{fgcolor}
\includegraphics[width=0.7\textwidth,height=0.7\textheight]{figure/predinteractivemat-1} 

\end{knitrout}

\end{frame}
%%%%%%%%%%

\end{document}
