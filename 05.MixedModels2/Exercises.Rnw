\documentclass[12pt,a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz}
%\usepackage{silence}
\usepackage{mdframed}
%\WarningFilter{mdframed}{You got a bad break}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
\usepackage{color}
\colorlet{exampcol}{blue!10}
\usepackage{multicol}
\usepackage{booktabs}

\usepackage{exercise}%[noanswer]

\usepackage[autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=black
}

\title{Exercises for linear mixed effect models, part 2}
\date{\today}
\author{Timoth\'ee Bonnet}


\begin{document}

<<echo=FALSE>>=
options(digits = 4) 
@

\maketitle

\tableofcontents
\ListOfExerciseInToc
\ExerciseLevelInToc{subsubsection}

\clearpage


\section{Uncertainty in random effects}
\subsection{Warming-up}

\begin{Exercise}[difficulty=1, title={Reading a summary in lme4}]
\begin{enumerate}
  \item Load the dataset "thorndata.txt" to fit a linear model of "herbivory" as a function of "thorndensity". What is the estimate for the slope?\\
  \item Add a random effect for site How does the estimate for the slope changes?\\
  \item How much variation is explained by differences among blocks? Is there a measure of uncertainty for this estimate?
\end{enumerate}
\end{Exercise}

\begin{Answer}
Part 1.
<<>>=
thorns <- read.table("thorndata.txt", header = TRUE)
lm(herbivory ~ thorndensity, data=thorns)
@
The slope is \Sexpr{coef(lm(herbivory ~ thorndensity, data=thorns))[2]}.\\

Part 2.
<<>>=
library(lme4)
summary(lmer(herbivory ~ thorndensity + (1|site), data=thorns))
@
The slope is now \Sexpr{coef(lmer(herbivory ~ thorndensity + (1|site), data=thorns))[2]}.\\

Part 3.
<<eval=FALSE>>=
summary(lmer(herbivory ~ thorndensity + (1|site), data=thorns))
as.numeric(VarCorr(lmer(herbivory ~ thorndensity + (1|site), data=thorns))$site)
@
The variance explained by block is \Sexpr{as.numeric(VarCorr(lmer(herbivory ~ thorndensity + (1|site), data=thorns))$block)} (careful, if you extract the standard deviation (Std.Dev.) you need to square it to obtain a variance.). There is no measure of uncertainty for the estimate of variance in block. In the \texttt{summmary} the \texttt{Std.Dev.} is simply the square root of \texttt{Variance}.
\end{Answer}

\subsection{Confidence intervals and Tests}
Sometimes random effects are part of the experimental design and are in the models only to control for confounding effects. But sometimes we care about their value or their statistical significance.


\begin{Exercise}[difficulty=1, title={CI for variance components in lme4}]
Use the function \texttt{confint} to estimate confidence intervals for the variance component for "site".
\end{Exercise}
\begin{Answer}
<<>>=
lmm1 <- lmer(herbivory ~ thorndensity + (1|site), data=thorns)
conf <- confint(lmm1)
conf[1,]^2
@
\end{Answer}



\begin{Exercise}[difficulty=1, title={Testing variance components in lme4}]
Use the function anova to test the statistical significance of the random effect "site" in the thorn dataset. 
\end{Exercise}
\begin{Answer}
<<>>=
lm0 <- lm(herbivory ~ thorndensity , data=thorns)
lmm1 <- lmer(herbivory ~ thorndensity + (1|site), data=thorns)

anova(lm0, lmm1)#doesn't work!
anova(lmm1, lm0)# mixed model must go first!
@
The p-value you get is \Sexpr{ anova(lmm1, lm0)$`Pr(>Chisq)`[2]}, however, be aware this is a conservative estimate!
\end{Answer}

\begin{Exercise}[difficulty=3, title={Does null-hypothesis testing work for random effect?}]
In principle we want p-values to follow a uniform distribution under the null-hypothesis; in particular the frequency of p-values below 0.05 should be 0.05 when the effect tested for is absent. Is it the case for tests of random intercepts?
Simulate some data sets with a random intercept that has a variance of zero,  test the significance of this random effect with anova and record the p-values.
You can use the following simulation template:

<<eval=FALSE>>=
RandomVariance <- 0
sampsize <- 500
nbblocks <- 30

pvals <- vector(length = 1000)

for (i in 1:1000)
{
  x <- rnorm(sampsize,mean = 4, sd=0.25)
  block <- sample(x = 1:nbblocks, size = sampsize, replace = TRUE)
  blockvalues <- rnorm(n = nbblocks, mean = 0, sd = sqrt(RandomVariance))
  y <- 8 - x + blockvalues[block] + rnorm(sampsize,0,1)
  dat <- data.frame(response = y, predictor = x, block=block)
  
  XXX <- lm(XXX)
  XXX <- lmer(XXX)
  XXX <- anova(XXX)
  XXX
}
@


\end{Exercise}
\begin{Answer}
<<eval=FALSE>>=

set.seed(1234)
RandomVariance <- 0
sampsize <- 500
nbblocks <- 30

pvals <- vector(length = 1000)
altpvals <- vector(length = 1000)
for (i in 1:1000)
{
  x <- rnorm(sampsize,mean = 4, sd=0.25)
block <- sample(x = 1:nbblocks, size = sampsize, replace = TRUE)
blockvalues <- rnorm(n = nbblocks, mean = 0, sd = sqrt(RandomVariance))
y <- 8 - x + blockvalues[block] + rnorm(sampsize,0,1)
dat <- data.frame(response = y, predictor = x, block=block)
lm0 <- lm(response ~ 1 + predictor, data=dat)
lmm0 <- lmer(response ~ 1 + predictor + (1|block), data=dat )
(LRT0 <- anova(lmm0, lm0)) #mixed model must come first!
pvals[i] <- LRT0$`Pr(>Chisq)`[2] # the p-value
altpvals[i] <- 1-pchisq(LRT0$Chisq[2],0.5) # a better p-value
}
hist(pvals)
hist(altpvals)

mean(pvals<0.05)
mean(altpvals<0.05)
@
\end{Answer}


\begin{Exercise}[difficulty=2, title={Do kangaroos have personalities?}]
<<echo=FALSE>>=

@

Use the function anova to test the statistical significance of the random effect "years" and "location". What are the p-values?
How are the p-values calculated here and should you trust this calculation?
\end{Exercise}
\begin{Answer}
<<>>=
smm <- read.csv("Data/smm.csv")
head(smm)
summary(lmm0 <- lmer(y ~ 1+x + (1+x|year)+ (1|location), data=smm))
@
\end{Answer}

\begin{Exercise}[difficulty=2, title={Testing variance components in MCMCglmm}]
lme4 can have difficulties estimating random effect parameters when models get a bit complex. An very powerful alternative, I recommend MCMCglmm. Try and fit a model of y with x as a fixed effect, and year and location as random effects. Use summary and plot to discuss the importance of the random effects.
\end{Exercise}


\section{Beyond random intercepts}

So far we have considered random effects around intercepts only (that is the meaning of the "1" in the lme4 syntax (1$\mid$ re)). But random effects can be around fixed effects. You may have heard of "random interactions", "random slopes", "random regressions"\dots

<<echo=FALSE, eval=FALSE>>=
modb <- read.table("modbeetles.txt", header = T)
head(modb)


library(lme4)

summary(lmer(Wo ~ 1 + host + (1|IDf), data = modb))

summary(lmer(Wo ~ 1 + host + (1+host|IDf), data = modb))

anob <- modb[,c("IDf", "host", "Wo", "date.mated")]
names(anob) <- c("parent", "environment", "mass", "cage")

anob$parent <- as.numeric(anob$parent)
anob$cage <- as.numeric(anob$cage)
anob$mass <- (anob$mass - 1) *10 +rnorm(nrow(anob), 0, 0.1)
head(anob)

summary(lmer(mass ~ 1 + environment + (1+environment|parent) + (1|cage), data = anob))
summary(lmer(mass ~ 1 + environment + (0+environment|parent) + (1|cage), data = anob))

summary(lmm2 <- lmer(mass ~ 1 + environment + (0+environment|parent) + (1|cage), data = anob))

plot(ranef(lmm2)$parent)

trs <- matrix(c(1,1, 0,1), nrow = 2)
covie <- -0.58*sqrt(1.0830*6.4103)
vcovie <- matrix(c(6.4103, covie, covie, 1.0830), nrow = 2)

newvcov <- trs %*% vcovie %*% t(trs)
newcor <- newvcov[1,2]/sqrt(newvcov[1,1]*newvcov[2,2])

write.csv(anob, "Data/beetles.csv", row.names = FALSE, quote = FALSE)
@



\begin{Exercise}[difficulty=2, title={Beetles: build a model}]
Load the dataset "beetles.csv". It contains (fake) data from an (real) experiment on gene-by-environment interactions. The variable of interest is the mass of beetles born in two different environments, from different parents, and in different cages. Assuming that we can measure genetic varition with parent random effects, we wonder if different genomes respond differently to different environments.
\textbf{Build the model corresponding to this question in lme4.}

(hints: you could start from a lm() of mass modeled by environment, then add random intercepts, and finally a little something more).
\end{Exercise}

\begin{Exercise}[difficulty=2, title={Beetles: look at the model}]
What are the variances related to genetic differences? How are they correlated? Does genetic variation explain a lot of the total variation we observe? Try and draw a representation of genetic variation in the two environments. 
\end{Exercise}

\begin{Exercise}[difficulty=3, title={Beetles: interpret}]
Interpret model outputs (use raw numbers and / or graphes) to answer the following:
Is there evidence for genetic variation? Do the two environment differ in their effects on beetles? \\
Is there evidence for genetic variation in the response to the environment? \\
Does that mean that genomes good at environment 1 are bad at environment 2?
\end{Exercise}

\subsection{Correlated random effects}
In all of the above, we have assumed that random effect levels to be perfectly correlated (e.g., observations from the same year) or not at all correlated (e.g., observations from different years). It can be very interesting to allow for intermediate values, in particular for models of spatio-temporal autocorrelation, phylogenetics, quantitative genetics.



\end{document}
