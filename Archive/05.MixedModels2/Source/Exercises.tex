\documentclass[12pt,a4paper]{scrartcl}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz}
%\usepackage{silence}
\usepackage{mdframed}
%\WarningFilter{mdframed}{You got a bad break}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{listings}
\usepackage{color}
\colorlet{exampcol}{blue!10}
\usepackage{multicol}
\usepackage{booktabs}

\usepackage[noanswer]{exercise}%[noanswer]

\usepackage[autostyle, english = american]{csquotes}
\MakeOuterQuote{"}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=black
}

\title{Exercises for linear mixed effect models, part 2}
\date{\today}
\author{Timoth\'ee Bonnet}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}



\maketitle

\tableofcontents
\ListOfExerciseInToc
\ExerciseLevelInToc{subsubsection}

\clearpage


\section{Uncertainty in random effects}
\subsection{Warming-up}

\begin{Exercise}[difficulty=1, title={Reading a summary in lme4}]
\begin{enumerate}
  \item Load the dataset "thorndata.txt" to fit a linear model of "herbivory" as a function of "thorndensity". What is the estimate for the slope?\\
  \item Add a random effect for site How does the estimate for the slope changes?\\
  \item How much variation is explained by differences among blocks? Is there a measure of uncertainty for this estimate?
\end{enumerate}
\end{Exercise}

\begin{Answer}
Part 1.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{thorns} \hlkwb{<-} \hlkwd{read.table}\hlstd{(}\hlstr{"thorndata.txt"}\hlstd{,} \hlkwc{header} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlkwd{lm}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity,} \hlkwc{data}\hlstd{=thorns)}
\end{alltt}
\begin{verbatim}
## 
## Call:
## lm(formula = herbivory ~ thorndensity, data = thorns)
## 
## Coefficients:
##  (Intercept)  thorndensity  
##        3.256         0.252
\end{verbatim}
\end{kframe}
\end{knitrout}
The slope is 0.2524.\\

Part 2.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(lme4)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Loading required package: Matrix}}\begin{alltt}
\hlkwd{summary}\hlstd{(}\hlkwd{lmer}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{site),} \hlkwc{data}\hlstd{=thorns))}
\end{alltt}
\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: herbivory ~ thorndensity + (1 | site)
##    Data: thorns
## 
## REML criterion at convergence: 165.3
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.488 -0.606  0.109  0.523  2.873 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  site     (Intercept) 2.129    1.459   
##  Residual             0.238    0.488   
## Number of obs: 100, groups:  site, 5
## 
## Fixed effects:
##              Estimate Std. Error t value
## (Intercept)     7.765      0.844    9.20
## thorndensity   -0.919      0.139   -6.63
## 
## Correlation of Fixed Effects:
##             (Intr)
## thorndensty -0.632
\end{verbatim}
\end{kframe}
\end{knitrout}
The slope is now NULL.\\

Part 3.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(}\hlkwd{lmer}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{site),} \hlkwc{data}\hlstd{=thorns))}
\hlkwd{as.numeric}\hlstd{(}\hlkwd{VarCorr}\hlstd{(}\hlkwd{lmer}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{site),} \hlkwc{data}\hlstd{=thorns))}\hlopt{$}\hlstd{site)}
\end{alltt}
\end{kframe}
\end{knitrout}
The variance explained by block is  (careful, if you extract the standard deviation (Std.Dev.) you need to square it to obtain a variance.). There is no measure of uncertainty for the estimate of variance in block. In the \texttt{summmary} the \texttt{Std.Dev.} is simply the square root of \texttt{Variance}.
\end{Answer}

\subsection{Confidence intervals and Tests}
Sometimes random effects are part of the experimental design and are in the models only to control for confounding effects. But sometimes we care about their value or their statistical significance.


\begin{Exercise}[difficulty=1, title={CI for variance components in lme4}]
Use the function \texttt{confint} to estimate confidence intervals for the variance component for "site".
\end{Exercise}
\begin{Answer}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lmm1} \hlkwb{<-} \hlkwd{lmer}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{site),} \hlkwc{data}\hlstd{=thorns)}
\hlstd{conf} \hlkwb{<-} \hlkwd{confint}\hlstd{(lmm1)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Computing profile confidence intervals ...}}\begin{alltt}
\hlstd{conf[}\hlnum{1}\hlstd{,]}\hlopt{^}\hlnum{2}
\end{alltt}
\begin{verbatim}
##  2.5 % 97.5 % 
## 0.5247 8.1932
\end{verbatim}
\end{kframe}
\end{knitrout}
\end{Answer}



\begin{Exercise}[difficulty=1, title={Testing variance components in lme4}]
Use the function anova to test the statistical significance of the random effect "site" in the thorn dataset. 
\end{Exercise}
\begin{Answer}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lm0} \hlkwb{<-} \hlkwd{lm}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity ,} \hlkwc{data}\hlstd{=thorns)}
\hlstd{lmm1} \hlkwb{<-} \hlkwd{lmer}\hlstd{(herbivory} \hlopt{~} \hlstd{thorndensity} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{site),} \hlkwc{data}\hlstd{=thorns)}

\hlkwd{anova}\hlstd{(lm0, lmm1)}\hlcom{#doesn't work!}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error: \$ operator not defined for this S4 class}}\begin{alltt}
\hlkwd{anova}\hlstd{(lmm1, lm0)}\hlcom{# mixed model must go first!}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# refitting model(s) with ML (instead of REML)}}\begin{verbatim}
## Data: thorns
## Models:
## lm0: herbivory ~ thorndensity
## lmm1: herbivory ~ thorndensity + (1 | site)
##      Df AIC BIC logLik deviance Chisq Chi Df Pr(>Chisq)    
## lm0   3 224 231   -109      218                            
## lmm1  4 172 182    -82      164  53.4      1    2.7e-13 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
The p-value you get is \ensuremath{2.6595\times 10^{-13}}, however, be aware this is a conservative estimate!
\end{Answer}

\begin{Exercise}[difficulty=3, title={Does null-hypothesis testing work for random effect?}]
In principle we want p-values to follow a uniform distribution under the null-hypothesis; in particular the frequency of p-values below 0.05 should be 0.05 when the effect tested for is absent. Is it the case for tests of random intercepts?
Simulate some data sets with a random intercept that has a variance of zero,  test the significance of this random effect with anova and record the p-values.
You can use the following simulation template:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{RandomVariance} \hlkwb{<-} \hlnum{0}
\hlstd{sampsize} \hlkwb{<-} \hlnum{500}
\hlstd{nbblocks} \hlkwb{<-} \hlnum{30}

\hlstd{pvals} \hlkwb{<-} \hlkwd{vector}\hlstd{(}\hlkwc{length} \hlstd{=} \hlnum{1000}\hlstd{)}

\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{1000}\hlstd{)}
\hlstd{\{}
  \hlstd{x} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(sampsize,}\hlkwc{mean} \hlstd{=} \hlnum{4}\hlstd{,} \hlkwc{sd}\hlstd{=}\hlnum{0.25}\hlstd{)}
  \hlstd{block} \hlkwb{<-} \hlkwd{sample}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{1}\hlopt{:}\hlstd{nbblocks,} \hlkwc{size} \hlstd{= sampsize,} \hlkwc{replace} \hlstd{=} \hlnum{TRUE}\hlstd{)}
  \hlstd{blockvalues} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlkwc{n} \hlstd{= nbblocks,} \hlkwc{mean} \hlstd{=} \hlnum{0}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(RandomVariance))}
  \hlstd{y} \hlkwb{<-} \hlnum{8} \hlopt{-} \hlstd{x} \hlopt{+} \hlstd{blockvalues[block]} \hlopt{+} \hlkwd{rnorm}\hlstd{(sampsize,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{)}
  \hlstd{dat} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{response} \hlstd{= y,} \hlkwc{predictor} \hlstd{= x,} \hlkwc{block}\hlstd{=block)}

  \hlstd{XXX} \hlkwb{<-} \hlkwd{lm}\hlstd{(XXX)}
  \hlstd{XXX} \hlkwb{<-} \hlkwd{lmer}\hlstd{(XXX)}
  \hlstd{XXX} \hlkwb{<-} \hlkwd{anova}\hlstd{(XXX)}
  \hlstd{XXX}
\hlstd{\}}
\end{alltt}
\end{kframe}
\end{knitrout}


\end{Exercise}
\begin{Answer}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{1234}\hlstd{)}
\hlstd{RandomVariance} \hlkwb{<-} \hlnum{0}
\hlstd{sampsize} \hlkwb{<-} \hlnum{500}
\hlstd{nbblocks} \hlkwb{<-} \hlnum{30}

\hlstd{pvals} \hlkwb{<-} \hlkwd{vector}\hlstd{(}\hlkwc{length} \hlstd{=} \hlnum{1000}\hlstd{)}
\hlstd{altpvals} \hlkwb{<-} \hlkwd{vector}\hlstd{(}\hlkwc{length} \hlstd{=} \hlnum{1000}\hlstd{)}
\hlkwa{for} \hlstd{(i} \hlkwa{in} \hlnum{1}\hlopt{:}\hlnum{1000}\hlstd{)}
\hlstd{\{}
  \hlstd{x} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(sampsize,}\hlkwc{mean} \hlstd{=} \hlnum{4}\hlstd{,} \hlkwc{sd}\hlstd{=}\hlnum{0.25}\hlstd{)}
\hlstd{block} \hlkwb{<-} \hlkwd{sample}\hlstd{(}\hlkwc{x} \hlstd{=} \hlnum{1}\hlopt{:}\hlstd{nbblocks,} \hlkwc{size} \hlstd{= sampsize,} \hlkwc{replace} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\hlstd{blockvalues} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlkwc{n} \hlstd{= nbblocks,} \hlkwc{mean} \hlstd{=} \hlnum{0}\hlstd{,} \hlkwc{sd} \hlstd{=} \hlkwd{sqrt}\hlstd{(RandomVariance))}
\hlstd{y} \hlkwb{<-} \hlnum{8} \hlopt{-} \hlstd{x} \hlopt{+} \hlstd{blockvalues[block]} \hlopt{+} \hlkwd{rnorm}\hlstd{(sampsize,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{)}
\hlstd{dat} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwc{response} \hlstd{= y,} \hlkwc{predictor} \hlstd{= x,} \hlkwc{block}\hlstd{=block)}
\hlstd{lm0} \hlkwb{<-} \hlkwd{lm}\hlstd{(response} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{predictor,} \hlkwc{data}\hlstd{=dat)}
\hlstd{lmm0} \hlkwb{<-} \hlkwd{lmer}\hlstd{(response} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{predictor} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{block),} \hlkwc{data}\hlstd{=dat )}
\hlstd{(LRT0} \hlkwb{<-} \hlkwd{anova}\hlstd{(lmm0, lm0))} \hlcom{#mixed model must come first!}
\hlstd{pvals[i]} \hlkwb{<-} \hlstd{LRT0}\hlopt{$}\hlstd{`Pr(>Chisq)`[}\hlnum{2}\hlstd{]} \hlcom{# the p-value}
\hlstd{altpvals[i]} \hlkwb{<-} \hlnum{1}\hlopt{-}\hlkwd{pchisq}\hlstd{(LRT0}\hlopt{$}\hlstd{Chisq[}\hlnum{2}\hlstd{],}\hlnum{0.5}\hlstd{)} \hlcom{# a better p-value}
\hlstd{\}}
\hlkwd{hist}\hlstd{(pvals)}
\hlkwd{hist}\hlstd{(altpvals)}

\hlkwd{mean}\hlstd{(pvals}\hlopt{<}\hlnum{0.05}\hlstd{)}
\hlkwd{mean}\hlstd{(altpvals}\hlopt{<}\hlnum{0.05}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{Answer}


\begin{Exercise}[difficulty=3, title={Do kangaroos have personalities?}]

We want to know whether the distance at which kangaroos run away when we approach is consistent within individuals. Load the dataset "roo.csv" and fit linear mixed models of "EscapeDistance" to find out. What variables to include? Does individual repeatability explain more variance than expected by randomly grouping observations? What is the repeatability of behaviour?
\end{Exercise}
\begin{Answer}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{roo} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlstr{"roo.csv"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

There is no simple answer to what model you should fit, because it depends what you think is part of intrinsic individual differences and what is not. The simplest model would be:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(}\hlkwd{lmer}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{id),} \hlkwc{data}\hlstd{=roo))}
\end{alltt}
\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: EscapeDistance ~ 1 + (1 | id)
##    Data: roo
## 
## REML criterion at convergence: 20185
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -4.432 -0.491  0.062  0.554  4.021 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 59.9     7.74    
##  Residual             38.3     6.19    
## Number of obs: 2909, groups:  id, 826
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   31.842      0.309     103
\end{verbatim}
\end{kframe}
\end{knitrout}
That's not necessarily wrong, but be aware of what residual and id variance contain here: age, sex, date, location... should they?

The following model is probably too complex:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(}\hlkwd{lmer}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlstd{Sex} \hlopt{+} \hlkwd{as.factor}\hlstd{(Age3)} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{id)} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{Mother),} \hlkwc{data}\hlstd{=roo))}
\end{alltt}
\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: EscapeDistance ~ 1 + Sex + as.factor(Age3) + (1 | id) + (1 |  
##     Mother)
##    Data: roo
## 
## REML criterion at convergence: 17007
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.942 -0.545 -0.004  0.583  6.884 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 10.29    3.21    
##  Mother   (Intercept)  2.49    1.58    
##  Residual             14.62    3.82    
## Number of obs: 2909, groups:  id, 826; Mother, 197
## 
## Fixed effects:
##                  Estimate Std. Error t value
## (Intercept)        24.571      0.264   93.21
## SexMale             1.671      0.300    5.57
## as.factor(Age3)1   14.652      0.217   67.40
## as.factor(Age3)2   18.594      0.357   52.14
## as.factor(Age3)3   21.644      1.166   18.57
## 
## Correlation of Fixed Effects:
##             (Intr) SexMal a.(A3)1 a.(A3)2
## SexMale     -0.567                       
## as.fct(A3)1 -0.326  0.097                
## as.fct(A3)2 -0.203  0.070  0.484         
## as.fct(A3)3 -0.060  0.023  0.141   0.169
\end{verbatim}
\end{kframe}
\end{knitrout}
indeed, "sex" and "Mother" (identity of an individual's mother) are part of an individual identity. Correcting for those will likely reduce the id variance. However, I think it makes sense to correct for age.


Maybe a good model would be:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(}\hlkwd{lmer}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlkwd{as.factor}\hlstd{(Age3)} \hlopt{+} \hlstd{Julian} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{Year)} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{id) ,} \hlkwc{data}\hlstd{=roo))}
\end{alltt}
\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: EscapeDistance ~ 1 + as.factor(Age3) + Julian + (1 | Year) +  
##     (1 | id)
##    Data: roo
## 
## REML criterion at convergence: 16982
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.789 -0.570  0.004  0.568  6.828 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  id       (Intercept) 13.236   3.638   
##  Year     (Intercept)  0.823   0.907   
##  Residual             13.985   3.740   
## Number of obs: 2909, groups:  id, 826; Year, 8
## 
## Fixed effects:
##                  Estimate Std. Error t value
## (Intercept)      19.28062    0.78098   24.69
## as.factor(Age3)1 16.20258    0.24313   66.64
## as.factor(Age3)2 20.43964    0.39803   51.35
## as.factor(Age3)3 23.78528    1.20335   19.77
## Julian            0.02646    0.00285    9.29
## 
## Correlation of Fixed Effects:
##             (Intr) a.(A3)1 a.(A3)2 a.(A3)3
## as.fct(A3)1 -0.503                        
## as.fct(A3)2 -0.382  0.581                 
## as.fct(A3)3 -0.169  0.244   0.253         
## Julian      -0.877  0.443   0.346   0.154
\end{verbatim}
\end{kframe}
\end{knitrout}
(but it is not unambiguous; you can disagree).

From there, we can test the statistical significance of repeatability as:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{lmfull} \hlkwb{<-} \hlkwd{lmer}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlkwd{as.factor}\hlstd{(Age3)} \hlopt{+} \hlstd{Julian} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{Year)} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{id) ,} \hlkwc{data}\hlstd{=roo)}
\hlstd{lmreduced} \hlkwb{<-} \hlkwd{lmer}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlkwd{as.factor}\hlstd{(Age3)} \hlopt{+} \hlstd{Julian} \hlopt{+} \hlstd{(}\hlnum{1}\hlopt{|}\hlstd{Year) ,} \hlkwc{data}\hlstd{=roo)}
\hlkwd{anova}\hlstd{(lmfull, lmreduced)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# refitting model(s) with ML (instead of REML)}}\begin{verbatim}
## Data: roo
## Models:
## lmreduced: EscapeDistance ~ 1 + as.factor(Age3) + Julian + (1 | Year)
## lmfull: EscapeDistance ~ 1 + as.factor(Age3) + Julian + (1 | Year) + 
## lmfull:     (1 | id)
##           Df   AIC   BIC logLik deviance Chisq Chi Df Pr(>Chisq)    
## lmreduced  7 17793 17834  -8889    17779                            
## lmfull     8 16988 17036  -8486    16972   806      1     <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}

and estimate repeatability:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{as.numeric}\hlstd{(}\hlkwd{VarCorr}\hlstd{(lmfull)[}\hlnum{1}\hlstd{])}\hlopt{/}\hlstd{(}\hlkwd{as.numeric}\hlstd{(}\hlkwd{VarCorr}\hlstd{(lmfull)[}\hlnum{1}\hlstd{])}\hlopt{+}
                                  \hlkwd{as.numeric}\hlstd{(}\hlkwd{VarCorr}\hlstd{(lmfull)[}\hlnum{2}\hlstd{])}\hlopt{+}
                                  \hlkwd{sigma}\hlstd{(lmfull)}\hlopt{^}\hlnum{2}\hlstd{)}
\end{alltt}
\begin{verbatim}
## [1] 0.472
\end{verbatim}
\end{kframe}
\end{knitrout}

\end{Answer}

\begin{Exercise}[difficulty=2, title={Testing variance components in MCMCglmm}]
lme4 can have difficulties estimating random effect parameters when models get a bit complex. An very powerful alternative, I recommend MCMCglmm. Try and fit one of the kangaroo models. Use summary and plot to discuss the importance of the random effects.
\end{Exercise}
\begin{Answer}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(MCMCglmm)}
\hlstd{mcmod} \hlkwb{<-} \hlkwd{MCMCglmm}\hlstd{(EscapeDistance} \hlopt{~} \hlnum{1} \hlopt{+} \hlkwd{as.factor}\hlstd{(Age3)} \hlopt{+} \hlstd{Julian ,} \hlkwc{random} \hlstd{=}\hlopt{~} \hlstd{Year} \hlopt{+} \hlstd{id ,} \hlkwc{data}\hlstd{=roo)}
\hlkwd{summary}\hlstd{(mcmod)}
\hlkwd{plot}\hlstd{(mcmod)}
\hlstd{repeatability} \hlkwb{<-} \hlstd{mcmod}\hlopt{$}\hlstd{VCV[,}\hlstr{"id"}\hlstd{]}\hlopt{/}\hlstd{(mcmod}\hlopt{$}\hlstd{VCV[,}\hlstr{"id"}\hlstd{]}\hlopt{+}\hlstd{mcmod}\hlopt{$}\hlstd{VCV[,}\hlstr{"Year"}\hlstd{]}\hlopt{+}\hlstd{mcmod}\hlopt{$}\hlstd{VCV[,}\hlstr{"units"}\hlstd{])}
\hlkwd{plot}\hlstd{(repeatability)}
\hlkwd{mean}\hlstd{(repeatability);} \hlkwd{HPDinterval}\hlstd{(repeatability)}
\end{alltt}
\end{kframe}
\end{knitrout}
\end{Answer}


\section{Beyond random intercepts}

So far we have considered random effects around intercepts only (that is the meaning of the "1" in the lme4 syntax (1$\mid$ re)). But random effects can be around fixed effects. You may have heard of "random interactions", "random slopes", "random regressions"\dots





\begin{Exercise}[difficulty=2, title={Beetles: build a model}]
Load the dataset "beetles.csv". It contains (fake) data from an (real) experiment on gene-by-environment interactions. The variable of interest is the mass of beetles born in two different environments, from different parents, and in different cages. Assuming that we can measure genetic varition with parent random effects, we wonder if different genomes respond differently to different environments.
\textbf{Build the model corresponding to this question in lme4.}

(hints: you could start from a lm() of mass modeled by environment, then add random intercepts, and finally a little something more).
\end{Exercise}

\begin{Exercise}[difficulty=2, title={Beetles: look at the model}]
What are the variances related to genetic differences? How are they correlated? Does genetic variation explain a lot of the total variation we observe? Try and draw a representation of genetic variation in the two environments. 
\end{Exercise}

\begin{Exercise}[difficulty=3, title={Beetles: interpret}]
Interpret model outputs (use raw numbers and / or graphes) to answer the following:
Is there evidence for genetic variation? Do the two environment differ in their effects on beetles? \\
Is there evidence for genetic variation in the response to the environment? \\
Does that mean that genomes good at environment 1 are bad at environment 2?
\end{Exercise}

\subsection{Correlated random effects}
In all of the above, we have assumed that random effect levels to be perfectly correlated (e.g., observations from the same year) or not at all correlated (e.g., observations from different years). It can be very interesting to allow for intermediate values, in particular for models of spatio-temporal autocorrelation, phylogenetics, quantitative genetics.



\end{document}
