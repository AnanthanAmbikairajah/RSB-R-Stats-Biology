\documentclass{beamer}


\usepackage{alltt}%
\usetheme{Boadilla}
\usecolortheme{seahorse}

%\usepackage{listings}
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\usepackage[utf8]{inputenc}
\usepackage{default}

\usepackage{xcolor}%for color mixing

\usepackage{amsmath}%
\usepackage{amsfonts}%
\usepackage{amssymb}%
\usepackage{graphicx}

\usepackage{tikz}
\usepackage{multirow}
\usepackage{booktabs}

\setbeamertemplate{itemize/enumerate body begin}{\small}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title[Logistic regression]{Generalized linear models and the logistic regression}
\author{Timoth\'ee Bonnet}
\date{\today}

\begin{document}

%\lstset{language=R}%code

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{}
    \tableofcontents[currentsection,sectionstyle=show/show,subsectionstyle=show/shaded/hide]% down vote\tableofcontents[currentsection,currentsubsection,hideothersubsections,sectionstyle=show/hide,subsectionstyle=show/shaded/hide] 
  \end{frame}
}

<<Plot Options, echo=FALSE, message=FALSE>>=
#load(file = ".RData")
opts_knit$set(width=60)
opts_chunk$set(comment=NA, fig.width=8, fig.height=6, out.width='0.8\\textwidth',
               out.height='0.6\\textwidth',background='#D7DDEB', size="small")


szgr <- 2
szax <- 1.3
marr <- c(4, 4, 1, 1) + 0.1
setPar<-function(){
par(las=1,mar=marr, cex=szgr, cex.lab=szax , cex.axis=szax, lwd=2 ,pch=1, las=1)
}
setPar()
@

\begin{frame}{logiwhat?}

From Wikipedia:
\begin{quote}
The function was named in 1844 by Pierre François Verhulst, who studied it in relation to population growth. The initial stage of growth is approximately exponential (geometric); then, as saturation begins, the growth slows to linear (arithmetic), and at maturity, growth stops. Verhulst did not explain the choice of the term ``logistic", but it is presumably in contrast to the logarithmic curve and by analogy with arithmetic and geometric. His growth model is preceded by a discussion of arithmetic growth and geometric growth, and thus "logistic growth" is presumably named by analogy, logistic being from Ancient Greek logistikós, a traditional division of Greek mathematics. The term is unrelated to the military and management term logistics.
\end{quote}

The ``logit" function/unit/transform comes from the contraction of \textbf{log}istic un\textbf{it}.

\end{frame}
%%%%%%%%%%%%%%%


\begin{frame}{}
\maketitle

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{A simple linear model}
  \textbf{{\color{purple}{Response}} = {\color{blue}{Intercept}} + {\color{red}{Slope}} $\times$ {\color{orange}{Predictor}} + {\color{gray}{Error}}} \\

  <<lmprinc, echo=FALSE, dev='tikz'>>=
    setPar()
    set.seed(123)
    x <- rnorm(20)
    y <- 1 + x + rnorm(20)
    plot(x, y, xlab="\\color{orange}{Predictor}", ylab="\\color{purple}{Response}")
    lm0 <- lm(y~x)
    abline(lm0, col="red", lwd=5)
    abline(h=coef(lm0)[1], lty=2, col="blue", lwd=5)
    newdat <- data.frame(x=seq(-2, 2, length.out = 100))
    newdat <- cbind(newdat,predict(lm0, se.fit = TRUE, newdata = newdat))
    newdat$CIu <- newdat$fit+newdat$se.fit*2
    newdat$CIl <- newdat$fit-newdat$se.fit*2
    polygon(x=c(newdat$x,rev(newdat$x)), y=c(newdat$CIl,rev(newdat$CIu)), col = rgb(0.8,0,0,0.2), border =NA)
    abline(v=0)
    abline(h=0)

    arrows(x0 = x, y0=y, y1=lm0$fitted.values, code=0, col="gray", lwd=3)
  @
\end{frame}
%%%%%%%%%%%

\begin{frame}[fragile]{A simple linear model failure: binary data}

  <<binlmprinc, echo=FALSE, dev='tikz'>>=
    setPar()
    set.seed(123)
    x <- rnorm(30)
    latent <- 1 + 2*x + rnorm(30, sd = 0.5)
    y <- 1/(1+exp(-latent))
    obs <- sapply(y, FUN=function(x){rbinom(1,1,x)})
    plot(x, obs, xlab="\\color{orange}{Predictor}", ylab="\\color{purple}{Response}", xlim = c(-3,3), ylim=c(-0.5,1.5))
    lm0 <- lm(y~x)
    newdat <- data.frame(x=seq(-3, 3, length.out = 100))
    newdat <- cbind(newdat,predict(lm0, se.fit = TRUE, newdata = newdat))
    newdat$CIu <- newdat$fit+newdat$se.fit*2
    newdat$CIl <- newdat$fit-newdat$se.fit*2
    polygon(x=c(newdat$x,rev(newdat$x)), y=c(newdat$CIl,rev(newdat$CIu)), col = rgb(0.8,0,0,0.2), border =NA)
    abline(lm0, col="red", lwd=5)
    abline(h=coef(lm0)[1], lty=2, col="blue", lwd=5)
    abline(v=0)
    abline(h=0)

    arrows(x0 = x, y0=obs, y1=lm0$fitted.values, code=0, col="gray", lwd=3)
  @
  
\end{frame}
%%%%%%%%%%%

\begin{frame}{What we want our model to do}
\centering

<<echo=FALSE>>=
set.seed(123)
x <- rnorm(30)
y <- 1 + 2*x + rnorm(30, 0, 0.2)
obs <- sapply(y, function(x){rbinom(1, 1, prob = 1/(1+exp(-x)))})
lrm0 <- glm(obs ~ 1 + x, family = "binomial")
newdat <- data.frame(x=seq(-3, 3, length.out = 100))
prlrm0 <- cbind(newdat, predict(lrm0,newdata =newdat, type = "link", se.fit = TRUE) )
@

<<logreg1, dev='tikz', echo=FALSE, fig.keep='last', fig.width=8, fig.height=6, out.width="0.8\\textwidth">>=
setPar()
plot(x, obs, xlab="\\color{orange}{Predictor}", ylab="\\color{purple}{Response}", xlim = c(-3,3), ylim=c(-0.5,1.5))
abline(h=c(0,1))
abline(v=0)
ybt <- 1/(1+exp(-prlrm0$fit))
lines(x = prlrm0$x, ybt, lwd=5, col='red')

ybtCIu <- 1/(1+exp(-(prlrm0$fit+2*prlrm0$se.fit)))
ybtCIl <- 1/(1+exp(-(prlrm0$fit-2*prlrm0$se.fit)))

polygon(x=c(prlrm0$x,rev(prlrm0$x)), y=c(ybtCIl,rev(ybtCIu)), col = rgb(0.8,0,0,0.2), border =NA)

pres <- predict(lrm0, type = "response")
segments(x0=x, y1 = pres, y0=obs, col="gray")

@

\end{frame}
%%%%%%%%%%%%

\begin{frame}{What we want our model to do}
\centering
\includegraphics[width=0.5\textwidth]{figure/logreg1-1.pdf}

\begin{block}{What we need:}
  \begin{enumerate}[<+->]
    \item Convert the predictor open scale ($-\infty$ to $+\infty$) to a bounded scale (0 to 1)
    \item Acknowledge discrete data
    \item Response variability depends on expected value
  \end{enumerate}
\end{block}
\end{frame}
%%%%%%%%%%%

\begin{frame}{That is what a Generalized Linear Model does}

\begin{block}{Vocabulary warning}
  \begin{itemize}
    \item General Linear Model (=linear model with several responses, multivariate)
    \item \textbf{Generalized Linear Model (=non-normal errors, and uncertainty dependent on the mean)} 
  \end{itemize}
\end{block}

\pause

\begin{block}{What a GLM is:}
  \begin{enumerate}[<+->]
    \item \textbf{Linear function} (reponse = intercept + slope $\times$ predictor \dots)
    \item ``\textbf{Link function}" = a map between the linear function ($-\infty$ to $+\infty$) and a probability distribution (from 0 to 1 for Bernouilli)
    \item \textbf{Probability distribution} (Bernouilli, Binomial, Poisson\dots) thought to generate the data (either 0 or 1 for Bernouilli)
  \end{enumerate}
\pause[\thebeamerpauses]

GLMs fit continuous expected response; we observe discrete realizations
\end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{What to do with logistic regression}
\centering
\only<1-2>{\includegraphics[width=0.5\textwidth]{figure/logreg1-1.pdf}}

\only<3>{
<<logreg2, dev='tikz', echo=FALSE, fig.keep='last', fig.width=8, fig.height=6, out.width="0.5\\textwidth">>=
par(las=1)
plot(x, obs, ylim = c(-0.5,1.5), xlim=c(-3,3), xlab="Predictor", ylab="Response")
abline(h=c(0,1))
abline(v=0)
ybt <- 1/(1+exp(-prlrm0$fit))
lines(x = prlrm0$x, ybt, lwd=5, col='red')

ybtCIu <- 1/(1+exp(-(prlrm0$fit+2*prlrm0$se.fit)))
ybtCIl <- 1/(1+exp(-(prlrm0$fit-2*prlrm0$se.fit)))

polygon(x=c(prlrm0$x,rev(prlrm0$x)), y=c(ybtCIl,rev(ybtCIu)), col = rgb(0.8,0,0,0.2), border =NA)
abline(v=-0.5, lwd=3, lty=2)
pres <- predict(lrm0, type = "response")
segments(x0=x, y1 = pres, y0=obs, col="gray")

@
}

\only<4>{
<<logreg3, dev='tikz', echo=FALSE, fig.keep='last', fig.width=8, fig.height=6, out.width="0.5\\textwidth">>=
par(las=1)
plot(x, obs, ylim = c(-0.5,1.5), xlim=c(-3,3), xlab="Predictor", ylab="Response")
abline(h=c(0,1))
abline(v=0)
ybt <- 1/(1+exp(-prlrm0$fit))
lines(x = prlrm0$x, ybt, lwd=5, col='red')

ybtCIu <- 1/(1+exp(-(prlrm0$fit+2*prlrm0$se.fit)))
ybtCIl <- 1/(1+exp(-(prlrm0$fit-2*prlrm0$se.fit)))

polygon(x=c(prlrm0$x,rev(prlrm0$x)), y=c(ybtCIl,rev(ybtCIu)), col = rgb(0.8,0,0,0.2), border =NA)
abline(v=-0.5, lwd=3, lty=2)
rect(xleft = c(-4, -0.5), ybottom = c(0,0.5), xright = c(-0.5,4), ytop = c(0.5,1), angle = 45, density = 10, col = "green")
rect(xleft = c(-4, -0.5), ybottom = c(0.5,0), xright = c(-0.5,4), ytop = c(1,0.5), angle = 135, density = 10, col = "red")
pres <- predict(lrm0, type = "response")
segments(x0=x, y1 = pres, y0=obs, col="gray")

@
}

\begin{block}{}
\begin{enumerate}[<+->]
  \item Response increase/decrease with increasing predictor?
  \item Estimate probability of 0/1 given a predictor value
  \item Predict 0/1 and classify predictor values (Machine Learning)
\end{enumerate}
\end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%

\end{document}